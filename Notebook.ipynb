{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Detetion Rates of sGRBs "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bd7351ca3213f6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook explore the detection rates of sGRBs by the Swift satellite.\n",
    "To do so, we utilise a form of Monte Carlo simulation to simulate a set of sGRBs, we then compare these to the known detected sGRBs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc37be901489f538"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing and cleaning the Swfit data   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de586857438c56a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "from astropy import units as u\n",
    "from scipy.integrate import quad\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31c45f4fc44ead48"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will start by importing and sorting through GRB data collected by the Swift Observatory (https://swift.gsfc.nasa.gov/archive/grb_table).\n",
    "We are going to be importing two data sets, one of all GRB under 2 seconds and the other of all GRB containing Redshift information. Its going to clean the data and filter what we need. Currently, it takes out all the sGRBs without redshift information and exports them to a separate file, this can be used for manually adding redshift data after the fact. It also exports a combined table containing all the sGRBs with redshift information based on the intrinsic time of the sGRBs. \n",
    "\n",
    "Conditions:\n",
    "Filters out GRB that do not contain redshift information\n",
    "calculates $T_{Intrinsic}$\n",
    "filters GRB $\\leq$ 2 seconds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22d43f50423f8cbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to clean numeric columns and keep the first number NEEDS TO BE CHANGED!!!!!!!\n",
    "def clean_numeric_column(df, column_name):\n",
    "    # Extract the first number from each entry\n",
    "    df[column_name] = df[column_name].astype(str).apply(\n",
    "        lambda x: re.findall(r'[\\d.]+', x)[0] if re.findall(r'[\\d.]+', x) else None)\n",
    "    return df\n",
    "\n",
    "# Function to convert columns to numeric values\n",
    "def convert_columns_to_numeric(df, columns_to_exclude):\n",
    "    for col in df.columns:\n",
    "        if col not in columns_to_exclude:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to calculate T_intrinsic\n",
    "def calculate_T_intrinsic(df, duration_col, redshift_col):\n",
    "    df['T_intrinsic'] = df[duration_col] / (1 + df[redshift_col])\n",
    "    return df\n",
    "\n",
    "def split_and_update_photon_index(df):\n",
    "    def split_photon_index(row):\n",
    "        # Convert row to string and split by comma\n",
    "        parts = str(row).split(',')\n",
    "\n",
    "        # Extract and clean up the number and text parts\n",
    "        number_part = parts[0].strip() if len(parts) > 0 else ''\n",
    "        text_part = parts[1].strip() if len(parts) > 1 else ''\n",
    "\n",
    "        return number_part, text_part\n",
    "\n",
    "    # Apply the function to split the column and add the results as new columns\n",
    "    df[['BAT Photon Index Value', 'BAT Photon Index Type']] = df['BAT Photon Index (15-150 keV) (PL = simple power-law, CPL = cutoff power-law)'].apply(split_photon_index).apply(pd.Series)\n",
    "\n",
    "    # Drop the original column\n",
    "    df.drop('BAT Photon Index (15-150 keV) (PL = simple power-law, CPL = cutoff power-law)', axis=1, inplace=True)\n",
    "    return df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "670a2b8b8b8b29b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load data\n",
    "grb_table_rf = pd.read_csv('Data/grb_table_rf.txt', sep='\\t')\n",
    "grb_table = pd.read_csv('Data/grb_table.txt', sep='\\t')\n",
    "\n",
    "\n",
    "# Clean and convert 'Redshift' column in grb_table_rf\n",
    "grb_table_rf = clean_numeric_column(grb_table_rf, 'Redshift')\n",
    "grb_table = clean_numeric_column(grb_table, 'Redshift')\n",
    "\n",
    "# Split the photon index column into two columns\n",
    "grb_table_rf = split_and_update_photon_index(grb_table_rf)\n",
    "grb_table = split_and_update_photon_index(grb_table)\n",
    "\n",
    "# List of columns to keep as strings\n",
    "columns_to_exclude = [\n",
    "    'GRB',\n",
    "    'BAT Photon Index Type',\n",
    "    'XRT RA (J2000)',\n",
    "    'XRT Dec (J2000)'\n",
    "]\n",
    "\n",
    "# Convert the columns to numeric values\n",
    "grb_table_rf = convert_columns_to_numeric(grb_table_rf, columns_to_exclude)\n",
    "grb_table = convert_columns_to_numeric(grb_table, columns_to_exclude)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55ee40aee639cdb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate T_intrinsic for grb_table_rf and grb_table\n",
    "grb_table_rf = calculate_T_intrinsic(grb_table_rf, 'BAT T90 [sec]', 'Redshift')\n",
    "grb_table = calculate_T_intrinsic(grb_table, 'BAT T90 [sec]', 'Redshift')\n",
    "\n",
    "# Filter both datasets for T_intrinsic times of 2 seconds or less\n",
    "filtered_grb_table_rf = grb_table_rf[grb_table_rf['T_intrinsic'] <= 2]\n",
    "filtered_grb_table = grb_table[grb_table['T_intrinsic'] <= 2]\n",
    "\n",
    "# Separate sGRBs without redshift information from grb_table and export\n",
    "sgrbs_without_redshift = grb_table[grb_table['Redshift'].isna()]\n",
    "\n",
    "# Merge the filtered datasets\n",
    "combined_grb_table = pd.concat([filtered_grb_table_rf, filtered_grb_table], ignore_index=True)\n",
    "\n",
    "# Removing potential duplicates\n",
    "combined_grb_table = combined_grb_table.drop_duplicates()\n",
    "\n",
    "# Reviewing and ensuring all columns are included after merge\n",
    "print(\"Columns in the combined dataset:\", combined_grb_table.columns)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b4bde90825ce609"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Exporting the combined dataset\n",
    "output_file_path = 'Data/combined_grb_table.txt'\n",
    "sgrbs_without_redshift.to_csv(output_file_path, sep='\\t', index=False)\n",
    "combined_grb_table.to_csv(output_file_path, sep='\\t', index=False)\n",
    "print(f\"Combined GRB data exported to {output_file_path}\")\n",
    "print(f\"Total Number of sGRB: {len(combined_grb_table)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3ca69c543cd3129"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fb12268a0c7e4bd9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulating sGRBs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e98fc4ef880f00c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have the data we need, we can start simulating sGRBs. We will be using a Monte Carlo simulation to simulate a set of sGRBs.\n",
    "\n",
    "For the parameters we will have teh following parameters:\n",
    "\n",
    "1. **Redshift** \n",
    "    \n",
    "        Our redshift is drawn from a probalbility distribtion. \n",
    "\n",
    "2. **Sky Position**\n",
    "\n",
    "3. **Interval between sGRBs**\n",
    "\n",
    "4. **Mass**\n",
    "\n",
    "5. **Beaming Angle*\n",
    "\n",
    "6. **Luminosity**\n",
    "\n",
    "        $$\\Phi(L_p) \\propto \\begin{cases} \n",
    "        \\left(\\frac{L_p}{L_*}\\right)^\\alpha & \\text{if } L_*/|\\Delta| < L_p \\leq L_*, \\\\\n",
    "        \\left(\\frac{L_p}{L_*}\\right)^\\beta & \\text{if } L_* < L_p \\leq \\Delta L_*, \n",
    "        \\end{cases}$$\n",
    "    \n",
    "7. **Log of the intrinsic time**\n",
    "\n",
    "We will be using the redshift distribution of sGRBs to simulate the redshift of the sGRBs. We will be using the duration distribution of sGRBs to simulate the duration of the sGRBs. We will be using the luminosity distribution of sGRBs to simulate the luminosity of the sGRBs. We will be using the flux distribution of sGRBs to simulate the flux of the sGRBs. We will be using the sky distribution of sGRBs to simulate the sky location of the sGRBs. We will be using the photon index distribution of sGRBs to simulate the photon index of the sGRBs. We will be using the fluence distribution of sGRBs to simulate the fluence of the sGRBs. We will be using the peak energy distribution of sGRBs to simulate the peak energy of the sGRBs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f4053f45b59ee69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Redshift Probability Distributions\n",
    "The redshift is drawn from a probability distribution.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b04627e2b565f67"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "zb = np.arange(0, 10.01, 0.01)\n",
    "\n",
    "Luminosity_swift = calculate_luminosity(zb, Flim, H, omega, alpha_min, beta_min, Eb_min, erg_swift_min, photons_swift_min)\n",
    "sensitivity_swift = compute_sensitivity(Luminosity_swift, L_star, delta1, delta2, alpha_mean, beta_mean)\n",
    "\n",
    "# File paths for uploaded data files\n",
    "data_files = [\n",
    "    'Mathematica_code/Data_Prob/Pz_Rh1_100.txt',\n",
    "    'Mathematica_code/Data_Prob/Pz_Rh1_1000.txt',\n",
    "    'Mathematica_code/Data_Prob/Pz_Rc1_100.txt',\n",
    "    'Mathematica_code/Data_Prob/Pz_Rc1_1000.txt',\n",
    "    'Data/Pz_Rc2_100.txt',\n",
    "    'Data/Pz_Rc2_1000.txt',\n",
    "    'Data/Pz_Rome_100.txt',\n",
    "    'Data/Pz_Rome_1000.txt'\n",
    "]\n",
    "\n",
    "# Labels for the data files\n",
    "labels = [\n",
    "    'Pz H06 100',\n",
    "    'Pz H06 1000',\n",
    "    'Pz Rc1 100',\n",
    "    'Pz Rc1 1000',\n",
    "    'Pz Rc2 100',\n",
    "    'Pz Rc2 1000',\n",
    "    'Pz Rome 100',\n",
    "    'Pz Rome 1000'\n",
    "]\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot data from each file\n",
    "for file, label in zip(data_files, labels):\n",
    "    data = pd.read_csv(file, header=None, sep='\\s+')\n",
    "    pz = data[1].values * sensitivity_swift\n",
    "    plt.plot(zb, pz, label=label, linewidth=2)\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Redshift', fontsize=16)\n",
    "plt.ylabel(' ', fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ecab03d944c1984"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
